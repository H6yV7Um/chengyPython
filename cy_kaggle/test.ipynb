{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8484856996935648\nSVC 0.8372244921121327\nKNN 0.8383985926682556\ndecision_tree 0.831682555896039\nrandom_forest 0.8272749971626376\nGBDT 0.848473215299058\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# 绘图\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_df = pd.read_csv('cy_kaggle/data/train.csv')\n",
    "test_df = pd.read_csv('cy_kaggle/data/test.csv')\n",
    "combine_df = pd.concat([train_df, test_df])\n",
    "\n",
    "train_df.groupby(train_df.Name.apply(lambda x: len(x)))['Survived'].mean().plot()\n",
    "combine_df['Name_len'] = combine_df['Name'].apply(lambda x: len(x))\n",
    "combine_df['Name_len'] = pd.qcut(combine_df['Name_len'], 5)\n",
    "\n",
    "combine_df.groupby(combine_df['Name']\n",
    "                   .apply(lambda x: x.split(', ')[1])\n",
    "                   .apply(lambda x: x.split('.')[0]))['Survived'].mean().plot()\n",
    "\n",
    "combine_df['Title'] = combine_df['Name'].apply(lambda x: x.split(', ')[1]).apply(lambda x: x.split('.')[0])\n",
    "combine_df['Title'] = combine_df['Title'].replace(\n",
    "    ['Don', 'Dona', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Sir', 'Dr'], 'Mr')\n",
    "combine_df['Title'] = combine_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "combine_df['Title'] = combine_df['Title'].replace(['the Countess', 'Mme', 'Lady', 'Dr'], 'Mrs')\n",
    "df = pd.get_dummies(combine_df['Title'], prefix='Title')\n",
    "combine_df = pd.concat([combine_df, df], axis=1)\n",
    "combine_df['Fname'] = combine_df['Name'].apply(lambda x: x.split(',')[0])\n",
    "combine_df['Familysize'] = combine_df['SibSp'] + combine_df['Parch']\n",
    "dead_female_Fname = list(set(combine_df[(combine_df.Sex == 'female') & (combine_df.Age >= 12)\n",
    "                                        & (combine_df.Survived == 0) & (combine_df.Familysize > 1)]['Fname'].values))\n",
    "survive_male_Fname = list(set(combine_df[(combine_df.Sex == 'male') & (combine_df.Age >= 12)\n",
    "                                         & (combine_df.Survived == 1) & (combine_df.Familysize > 1)]['Fname'].values))\n",
    "print(dead_female_Fname)\n",
    "combine_df['Dead_female_family'] = np.where(combine_df['Fname'].isin(dead_female_Fname), 1, 0)\n",
    "combine_df['Survive_male_family'] = np.where(combine_df['Fname'].isin(survive_male_Fname), 1, 0)\n",
    "combine_df = combine_df.drop(['Name', 'Fname'], axis=1)\n",
    "\n",
    "group = combine_df.groupby(['Title', 'Pclass'])['Age']\n",
    "combine_df['Age'] = group.transform(lambda x: x.fillna(x.median()))\n",
    "combine_df = combine_df.drop('Title', axis=1)\n",
    "combine_df['IsChild'] = np.where(combine_df['Age'] <= 12, 1, 0)\n",
    "combine_df['Age'] = pd.cut(combine_df['Age'], 5)\n",
    "combine_df = combine_df.drop('Age', axis=1)\n",
    "# combine_df['Familysize'] = np.where(combine_df['Familysize'] == 0, 'solo',\n",
    "#                                     np.where(combine_df['Familysize'] <= 3, 'normal', 'big'))\n",
    "# df = pd.get_dummies(combine_df['Familysize'], prefix='Familysize')\n",
    "# combine_df = pd.concat([combine_df, df], axis=1).drop(['SibSp', 'Parch', 'Familysize'], axis=1)\n",
    "\n",
    "combine_df['Low_Survival_Familysize'] = np.where(combine_df['Familysize'].isin([7, 8, 9, 10]), 1, 0)\n",
    "combine_df['Middle_Survival_Familysize'] = np.where(combine_df['Familysize'].isin([0, 4, 5, 6]), 1, 0)\n",
    "combine_df['High_Survival_Familysize'] = np.where(combine_df['Familysize'].isin([1, 2, 3]), 1, 0)\n",
    "combine_df = combine_df.drop(['SibSp', 'Parch', 'Familysize'], axis=1)\n",
    "\n",
    "combine_df['Ticket_Lett'] = combine_df['Ticket'].apply(lambda x: str(x)[0])\n",
    "combine_df['Ticket_Lett'] = combine_df['Ticket_Lett'].apply(lambda x: str(x))\n",
    "\n",
    "combine_df['High_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['1', '2', 'P']), 1, 0)\n",
    "combine_df['Low_Survival_Ticket'] = np.where(combine_df['Ticket_Lett'].isin(['A', 'W', '3', '7']), 1, 0)\n",
    "combine_df = combine_df.drop(['Ticket', 'Ticket_Lett'], axis=1)\n",
    "combine_df.Embarked = combine_df.Embarked.fillna('S')\n",
    "df = pd.get_dummies(combine_df['Embarked'], prefix='Embarked')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Embarked', axis=1)\n",
    "\n",
    "combine_df.Cabin = combine_df.Cabin.fillna('None')\n",
    "combine_df['Cabin_type'] = combine_df.Cabin.apply(lambda x: x[0])\n",
    "# df = pd.get_dummies(combine_df['Cabin_type'], prefix='Cabin')\n",
    "# combine_df = pd.concat([combine_df, df], axis=1).drop('Cabin_type', axis=1)\n",
    "\n",
    "combine_df['High_Survival_Cabin'] = np.where(combine_df['Cabin_type'].isin(['B', 'D', 'E']), 1, 0)\n",
    "combine_df['Middle_Survival_Cabin'] = np.where(combine_df['Cabin_type'].isin(['A', 'C', 'F', 'G']), 1, 0)\n",
    "combine_df['Low_Survival_Cabin'] = np.where(combine_df['Cabin_type'].isin(['N', 'T']), 1, 0)\n",
    "\n",
    "#combine_df['Cabin_isNull'] = np.where(combine_df['Cabin'].isnull(), 0, 1)\n",
    "combine_df = combine_df.drop('Cabin', axis=1)\n",
    "df = pd.get_dummies(combine_df['Pclass'], prefix='Pclass')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Pclass', axis=1)\n",
    "df = pd.get_dummies(combine_df['Sex'], prefix='Sex')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Sex', axis=1)\n",
    "combine_df['Fare'] = pd.qcut(combine_df.Fare, 3)\n",
    "df = pd.get_dummies(combine_df.Fare, prefix='Fare').drop('Fare_(-0.001, 8.662]', axis=1)\n",
    "#df = pd.get_dummies(combine_df.Fare, prefix='Fare')\n",
    "combine_df = pd.concat([combine_df, df], axis=1).drop('Fare', axis=1)\n",
    "\n",
    "features = combine_df.drop([\"PassengerId\", \"Survived\"], axis=1).columns\n",
    "combine_df.info()\n",
    "le = LabelEncoder()\n",
    "for feature in features:\n",
    "    le = le.fit(combine_df[feature])\n",
    "    combine_df[feature] = le.transform(combine_df[feature])\n",
    "X_all = combine_df.iloc[:891, :].drop([\"PassengerId\", \"Survived\"], axis=1)\n",
    "Y_all = combine_df.iloc[:891, :][\"Survived\"]\n",
    "X_test = combine_df.iloc[891:, :].drop([\"PassengerId\", \"Survived\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8484856996935648\nSVC 0.8372244921121327\nKNN 0.8383985926682556\ndecision_tree 0.831682555896039\nrandom_forest 0.8272749971626376\nGBDT 0.848473215299058\n"
     ]
    }
   ],
   "source": [
    "X_all.rename(\n",
    "    columns={'Fare_(-0.001, 8.662]': 'Fare_0', 'Fare_(8.662, 26.0]': 'Fare_1', 'Fare_(26.0, 512.329]': 'Fare_2'},\n",
    "    inplace=True)\n",
    "\n",
    "X_test.rename(\n",
    "    columns={'Fare_(-0.001, 8.662]': 'Fare_0', 'Fare_(8.662, 26.0]': 'Fare_1', 'Fare_(26.0, 512.329]': 'Fare_2'},\n",
    "    inplace=True)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(n_estimators=300, min_samples_leaf=4, class_weight={0: 0.745, 1: 0.255})\n",
    "gbdt = GradientBoostingClassifier(n_estimators=500, learning_rate=0.03, max_depth=3)\n",
    "xgbGBDT = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)\n",
    "clfs = [lr, svc, knn, dt, rf, gbdt, xgbGBDT]\n",
    "\n",
    "kfold = 10\n",
    "cv_results = []\n",
    "for classifier in clfs:\n",
    "    cv_results.append(cross_val_score(classifier, X_all, y=Y_all, scoring=\"accuracy\", cv=kfold, n_jobs=4))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "ag = [\"LR\", \"SVC\", 'KNN', 'decision_tree', \"random_forest\", \"GBDT\", \"xgbGBDT\"]\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\": cv_means, \"CrossValerrors\": cv_std,\n",
    "                       \"Algorithm\": ag})\n",
    "\n",
    "g = sns.barplot(\"CrossValMeans\", \"Algorithm\", data=cv_res, palette=\"Set3\", orient=\"h\", **{'xerr': cv_std})\n",
    "g.set_xlabel(\"Mean Accuracy\")\n",
    "g = g.set_title(\"Cross validation scores\")\n",
    "\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, estimators):\n",
    "        self.estimatos_names = []\n",
    "        self.estimatos = []\n",
    "        for i in estimators:\n",
    "            self.estimatos_names.append(i[0])\n",
    "            self.estimatos.append(i[1])\n",
    "        self.clf = LogisticRegression()\n",
    "    def fit(self, train_X, train_y):\n",
    "        for i in self.estimatos:\n",
    "            i.fit(train_X, train_y)\n",
    "        x = np.array([i.predict(train_X) for i in self.estimatos]).T\n",
    "        y = train_y\n",
    "        self.clf.fit(x, y)\n",
    "    def predict(self, x):\n",
    "        x = np.array([i.predict(x) for i in self.estimatos]).T\n",
    "        # print(x)\n",
    "        return self.clf.predict(x)\n",
    "    def score(self, x, y):\n",
    "        s = precision_score(y, self.predict(x))\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8484856996935648\nSVC 0.8372244921121327\nKNN 0.8383985926682556\ndecision_tree 0.831682555896039\nrandom_forest 0.8272749971626376\nGBDT 0.848473215299058\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(ag[i], cv_means[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.832\n"
     ]
    }
   ],
   "source": [
    "bag = Ensemble([('xgb', xgbGBDT), ('lr', lr), ('rf', rf), ('svc', svc), ('gbdt', gbdt)])\n",
    "score = 0\n",
    "for i in range(0, 10):\n",
    "    num_test = 0.20\n",
    "    X_train, X_cv, Y_train, Y_cv = train_test_split(X_all, Y_all, test_size=num_test)\n",
    "    bag.fit(X_train, Y_train)\n",
    "    #Y_test = bag.predict(X_test)\n",
    "    acc_xgb = round(bag.score(X_cv, Y_cv) * 100, 2)\n",
    "    score += acc_xgb\n",
    "print(score / 10)  #0.8786\n",
    "\n",
    "bag.fit(X_all,Y_all)\n",
    "y_predict = bag.predict(X_test)\n",
    "with open('cy_kaggle/data/new_svc_result.csv', 'w') as result_file:\n",
    "    result_file.write(\"PassengerId,Survived\" + \"\\n\")\n",
    "    for pid, flag in zip(test_df.values[:, 0], y_predict):\n",
    "        result_file.write(str(pid) + \",\" + str(int(flag)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
